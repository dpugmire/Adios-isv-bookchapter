\section{ADIOS I/O Abstraction}
\label{sec:adios}

A parallel application that produces data uses ADIOS to define \emph{variables} ($n$-dimensional distributed arrays of a particular type) and \emph{attributes} (labels associated with individual variables or the entire output data set).
It also specifies when the data is available for output. The output is organized around output \emph{Steps}, instead of individual variables.
A Step includes all the variables and attributes that are to be sent to the target at once.
There is nothing in the ADIOS interface that prescribes how to handle the data (e.g. data aggregation among the processes, targeting a single file or one file per process, handling multiple readers, and handling the disappearance of a potential reader).
These belong to the \emph{IO strategy} and are implemented in various ways by different Engines.
The user can control the behavior of the application by choosing a specific engine, and parameterizing it with available options. 

Similarly, a reading application only declares what data it wants to retrieve from a source, each process of the parallel application declaring what it needs, and when it expects the data to be in its memory.
The input is also organized around Steps, not individual variables. The semantics of the ADIOS API  ensure that a reader never gets into an inconsistent state where portion of the data of some variables belong to a certain step, and other portion to another step.

Analysis and visualization are typically data-hungry operations~\cite{Childs2010}. This makes scalable access to data key. In an in situ environment, the ability to maintain clear boundaries between simulation and analysis tasks can promote fault tolerance, interoperability, programmability and maintainability.  


The flexibility of the data movement abstractions provided by ADIOS makes it easy to integrate with analysis and visualization applications. The ``file-like'' API provided by ADIOS allows seamless reads from disk, from memory, or streaming over the network.
Likewise, on the write side, outputs produced by analysis and visualization applications can be written to disk, or shared with other applications through memory or streamed over the network. The abstraction used by ADIOS makes it easy to move data as it does something that the application is already doing, namely, reading and writing from files.

The abstraction provides the same access to data regardless of where the data are located, be it disk, memory or streaming. 
As examples, the  VisIt~\cite{HPV:VisIt} and ParaView~\cite{paraview} visualization tools have support for reading data from ADIOS in this manner.
Both tools provide access to ADIOS data using a data reader plugin.
The plugin reads the ADIOS data and creates mesh-based data that can be visualized by the VisIt and ParaView tools.
An example of VisIt visualizing streaming data is described in Section~\ref{sec:jaxa}.

When visualization is used in an in situ environment, the ability to have clear boundaries between the simulation and analysis and visualization, and rely on a middleware layer for the sharing and exchange of data is valuable in a number of ways. 
(1) It makes it much easier to reconfigure components in a workflow based on the needs of the scientific campaign. (2) Fault tolerance is increased because the simulation can be separated from the visualization. (3) The mechanism for sharing data between producer and consumer can more easily be modified, changed or replaced.

In the remainder of this section we describe ADIOS in more detail. In Section~\ref{sec:adios:engine} and~\ref{sec:adios:advanced} we describe the ADIOS engines used to move data and some advanced topics on reduction and data interpretation.
In Section~\ref{sec:adios:discussion} we discuss the characteristics of these engines and how they relate to visualization and analysis needs and costs. Finally, in Section~\ref{sec:adios:code} we show some code examples of how ADIOS is used for both data producers and data consumers.

\subsection{ADIOS Engines}
\label{sec:adios:engine}

The mechanism in ADIOS for moving data is called an \emph{engine}.
An engine is tasked with executing the I/O heavy operations associated with the movement of data. 
Each engine supports a unified interface that allows data producers to \emph{put} data, and data consumers to \emph{get} data. The details of moving the data between source and destination are left to particular implementation details of each engine.
ADIOS provides a number of engines, which are described below.

\subsubsection{File-based Engines}
ADIOS provides two types of engines for performing parallel IO of data to disk storage. 

\paragraph{\textbf{BPFile Engine}}
The BPFile engine is the default engine for storage.
The output file target is a directory, which contains both metadata and  data files. The number of files is tailored to the capability of the file system, not to the number of writers or readers, which ensures scalable I/O performance. The steps stored in a single file target, can be read by other applications step-by-step simultaneously. Therefore, this engine can be used for in situ processing through the file system.

\paragraph{\textbf{HDF5 Engine}}
This engine can be used to write and read HDF5 formatted files. It uses the Parallel HDF5 library, so it provides only a compatibility layer to process HDF5 files in an ADIOS application workflow and is only as scalable as the HDF5 library itself. Streaming access to data is not currently available, but will be available once it is supported by HDF5.
 
\subsubsection{Data Staging Engines}
Data staging is a generic concept in ADIOS for providing concurrent access to data to one or more consumers through memory or streamed over the network. It can map onto both time and space division of the taxonomy in Chapter~\ref{chapter:intro}. Data staging engines are typically used for doing in situ analysis and visualization and code coupling. With staging engines, the data producer will write the data using the ADIOS API. The data are then available to be read by the consumers using the ADIOS API. Each staging engine has the ability to move the data in different ways, which are described below.

\paragraph{\textbf{Scalable Staging Transport (SST)}}
The most versatile and flexible staging engine uses either RDMA, TCP, UDP, or shared memory to move data from a producer (parallel application) to other consumers (multiple independent parallel applications). Consumers can come and go dynamically without affecting the producer. The output step is buffered in the producer's memory, and readers pull out portions of the buffered data with RDMA operations or communicate with a thread in the producer to receive it via TCP. The requirement of all engines to always provide a consistent view of a step to a reader may result in blocking the producer from progressing if the consumer is slower than the producer. The SST writer engine aggregates metadata for every step, and shares it with all readers. Readers then issue remote reading operations based on the I/O pattern in metadata. This allows the I/O pattern to vary over time. SST also allows readers to disconnect and reconnect while writers keep writing.
To address different application requirements, the SST buffering policy can be configured at run-time. This includes keeping only the most recent step, buffering a fixed window of consecutive steps, or blocking until the step is consumed. In cases where strong coupling is required between applications, the buffer limit can be set to $1$, which ensures that every step is consumed by the reader before the producer moves to the next data step.
For use cases like interactive visualization, buffering only the latest step is useful since the user typically does not want to block the simulation while a particular time step is explored.
While SST aims to provide the flexibility for addressing various application requirements, the fact that it manages metadata for every single step may be overkill for uses cases where the metadata does not change frequently, or at all.
 
\paragraph{\textbf{Insitu-MPI}}
This engine focuses on the speed of data movement for use cases where the metadata is constant across the workflow and a single metadata aggregation at the first data step will suffice. After this first step, each writer and reader knows the exact I/O pattern and direct communication is performed using asynchronous send and receive operations using an MPI  communicator. Since it uses MPI, the producer and consumer applications must be launched within a single mpiexec command using the Multiple Program Multiple Data (MPMD) mode. The engine directly sends the application data to the consumer, hence, the producer is synchronized to the consumer at every step to avoid modifying the data before it is received. 
For very large applications with constant I/O patterns, the Insitu-MPI engine can provide CPU savings for metadata management. However, since it must be launched in MPMD mode under MPI, the flexibility of readers dynamically join or leave is not supported at run-time.


\paragraph{\textbf{Staging for Strong Coupling (SSC)}}
The SSC engine is also designed for applications that have constant metadata over time. Similar to the Insitu-MPI engine, the SSC engine aggregates metadata once on the first time step. The main differences between SSC and Insitu-MPI are that SSC uses one-sided MPI communication and that the producer output is buffered.
The one sided MPI paradigm does not require the send and receive calls to be paired. Instead, it allows direct access to remote memory of another process. The buffering of application data, on the other hand, enables the producer to continue with the computation while the data is transferred to the consumer. 
In very large scale coupling use cases this approach saves the overhead of one side waiting for the other side to complete the send and receive pairs, and makes it possible for applications to very quickly, and frequently exchange data. 


\paragraph{\textbf{DataMan}}
This engine focuses on providing good bandwidth over wide-area-networks (WAN. It uses the publish and subscribe communication mechanism of the ZeroMQ library and has been optimized specifically for long-distance low-latency data movement. Unlike other staging engines, such as SSC described above, DataMan does not guarantee that every data step is transferred. Instead, the subscriber is designed to read only the latest data steps, while ignoring the previous steps. This saves the two-way communications for checking step completion, which usually means several hundred milliseconds in inter-continental data transfers. Because of this, the data transfer latency is greatly reduced and can support near-real-time analysis better than other engines over the WAN.

\subsection{Advanced Data Management Services}
\label{sec:adios:advanced}
ADIOS has a number of internal and external supports for advanced management of data. These include data compression, and schemas for providing additional information about ADIOS data to help downstream processing applications, such as analysis and visualization to properly interpret the raw data.

\subsubsection{Data Compression}
ADIOS supports operators as a mechanism for performing calculations on the data before it is written by an engine.
A general purpose operator, called a Callback provides the user with the ability to perform arbitrary calculations and manipulations to the data inside the engine. Data compression is provided in ADIOS using this mechanism. It provides support for a number of different lossless and lossy compression methods, which are described below.

In the classical workflow for high-performance scientific simulations, the entire data set is written to storage after generation.
This will no longer be viable at the exascale, simply because the amount of data will swamp the filesystem.
To accelerate scientific discovery, we must prioritize information over data.
It will be vital to take advantage of a priori user information to prioritize the most useful data so that I/O can be completed under standard HPC time constraints.
(For example, on Summit, jobs are limited to 24 hours.)
One solution is data compression.
ADIOS supports storing or transporting data in compressed form to reduce the I/O cost while preserving key information, which in turns speed up simulations or in situ data analysis and visualization~\cite{chenunderstanding}.
Enabling compression requires minimal development effort from users.
Simply specifying an operator for each variable enables ADIOS to automatically compress or decompress at the point of data publication or subscription.
Lossless compressors such as BZip2~\cite{seward1996bzip2} preserve every bit of the data, but compression ratios observed in practice are minimal.
Lossy compressors such as MGARD~\cite{ ainsworth2018multilevel,ainsworth2019multilevel2,ainsworth2019multilevel}, SZ~\cite{di2016fast, liang2018efficient,tao2017significantly}, and ZFP~\cite{lindstrom2014fixed} provide much higher compression ratios (usually more than an order of magnitude than lossless), but information is lost.
However, most lossy compressors allow control of the loss through parameters, which can be easily set in ADIOS.
Also, as derived quantities in data are particular important for scientific discovery, one of the compressors supported by ADIOS, MGARD, can consider one or more relevant quantities of interest and reduce the data so as to preserve these quantities.
Furthermore, ADIOS supports the meta-compressor Blosc which provides further lossless compressors (Zstd, Snappy, BloscLZ, LZ4HC) as well as shuffle pre-conditioners.
In GPU-centric applications, using ADIOS with Blosc's threaded-chunked compressor variants regularly trades unutilized CPU-cycles for I/O speedup~\cite{Huebl2017}.


\subsubsection{Schemas}
Schemas provide the ability to annotate the semantics of the array-based layout of data in ADIOS.
These provide the meaning of each data array, and the relationship between groups of arrays in an ADIOS file or stream. 
This capability makes it easier for tools using ADIOS to be used together in, for example, a complex scientific workflow.
Two examples of such schemas are described below.

%% I guess there is no subsubsubsection...
%\subsubsubsection{ADIS Visualization Schema}
\paragraph{\textbf{ADIS Visualization Schema}}
%As simulations become more ambitious, the cost of running an irrelevant or buggy job increases proportionally.
%Real-time graphical analysis of a simulation is a form of quality control, but to our knowledge, software tools which facilitate this have not been developed.
%The SST staging engine of ADIOS, along with the high-performance computer graphics library VTK-m can be glued together with the newly written ADIS library, so that real-time graphical analysis of a simulation can be performed.
%For example, using ADIS, we can visualize a timestep in an ODE or PDE solver \emph{as it is being computed}.
%This is an extremely useful quality control step, as in many contexts, timesteps occupy so much memory that they must be discarded, with only the final timestep being visualized.
%This is a very dangerous numerical simulation, with quality control only being done at the final state.
%The three technologies of ADIS, ADIOS, and VTK-m allows complete decoupling between numerical simulation and graphical quality control.
%Note that some hardware resources must be devoted to graphical analysis, but Amdahl's law suggests that the final performance cost will not be too great.


The Adaptable Data Interface for Services (ADIS) is a schema for describing mesh-based data that are used by visualisation tools. ADIS uses a JavaScript Object Notation (JSON) formatted strings to describe the content of ADIOS data. For example, for ADIOS data arrays representing field data on a uniform grid, the ADIS schema will specify that there is a uniform mesh of a given size, and the names of the arrays in the ADIOS stream for each field and the association on the mesh (e.g., zone centered, point centered, etc).
For more complex mesh types, like unstructured grids, ADIS specifies the names of the arrays for specifying the relevant mesh structures (e.g., point  coordinate values, cell information, etc).

ADIS also supports the creation of data sets from ADIOS in the VTK-m~\cite{moreland2016} format. Given a schema, and an ADIOS file/stream, ADIS will read data from ADIOS and construct the appropriate VTK-m data object.

\paragraph{\textbf{openPMD Schema}}

The Open Standard for Particle-Mesh Data Files (openPMD) is a schema for describing mesh- and particle-based data.
% standardized metadata to exchange, archive, reproduce, and visualize generated data products and automate scientific data workflows as a critical aspect in productive I/O
Its primary focus is the exchange, archival and replicability of scientific data via a minimal set of conventions and meta information.
The schema is defined in the so-called "base standard" and "extensions".
The former is agnostic of the data's scientific domain and can be automatically verified/parsed, visualized, scaled and dimensionally analyzed (describing units and quantities).
The base standard also provides means to document authorship, hardware and software environments towards reproducible research.
Based on this, standardized meta-information in openPMD schema "extensions" add further meaning for domain-scientists, e.g. by documenting algorithms and methods that generated a data set.

Contrary to visualization-focused and domain-specific schemas, openPMD is a notion for \textit{scientifically self-describing} data in general, providing a unified description for data in scientific workflows from source, over processing, analysis and visualization to archival in (open) data repositories.
% a unified description for post-processing, visualization and analysis.
% This standard tries to bridge the gap between the common "blob of data" and the algorithms, methods and/or schemes that created these.
openPMD is widely adopted in plasma-physics, particle-accelerator physics, photon-science, among others.\footnote{Curated list available at \url{https://github.com/openPMD/openPMD-projects}}
% Data analysis and Vis: VisIt, yt, domain-specific, ...
% converters: GPT, VTK-files, ...

The schema can be added to data described via hierarchical, self-describing (portable) data formats.
Open implementations are available in C++, Python and Fortran and currently range from MPI-parallel ADIOS1, ADIOS2 and HDF5 library backends to serial JSON files.
The openPMD schema is versioned, citable and developed on GitHub.
Its release is version 1.1.0 and data files using the schema are forward-updatable via lightweight meta-data transformations~\cite{HueblopenPMD}.
% GitHub-centric community contribution process


\subsection{Discussion}
\label{sec:adios:discussion}

\begin{figure}[t]
\sidecaption
\includegraphics[width=1\linewidth]{figures/ADIOS_workflow.png}
\caption{Example workflow using ADIOS for simulation coupling, in situ visualization, in transit visualization, and streaming of both simulation and experimental data over the WAN to a remote site for analysis.}
\label{fig:example_workflow}
\end{figure}

The number of engines available in ADIOS provides a large amount of flexibility when selecting a configuration. Further, multiple executables can be connected using the read/write API of an ADIOS engine to support a range of different types of workflows. The example workflow in Figure~\ref{fig:example_workflow} shows ADIOS (indicated with red arrows) being used as the data movement mechanism for a number of tasks. It is used to couple two simulations, in situ visualization on the HPC resource, in transit visualization on a cluster in the HPC center, and transfer data over the WAN to remote site for analysis. Additionally, data from a sensor/experiment is streamed over the WAN for analysis that uses simulation results.

When designing a visualization workflow, the choice of engine for each component is dependent on a number of factors. Broadly speaking these classes of visualization are post hoc, in situ (time division), and in transit (space division). Post hoc visualization is the traditional mode of visualization where the data are read from disk. As discussed in Chapter~\ref{chapter:intro}, in situ visualization, while a broadly defined term, is for simplicity, the case where the visualization and simulation use the same set of resources. In transit visualization uses two distinct sets of resources, one dedicated to the simulation and the other dedicated to the visualization. The network is used to transfer data between the two sets of resources. Below, we discuss these three modes from the ADIOS and visualization perspectives and the impact of choices made have on visualization functionality and performance.

\subsubsection{ADIOS Perspective}
From an ADIOS perspective, the following three characteristics are important: (1) data access and movement, (2) fault tolerance, and (3) programmability.

\paragraph{\textbf{Data Access and Movement}}
Data access is defined as how much of the total spatio-temporal data are available, as the temporal range of data that are available. Data movement is the amount of data that must be moved from producer to consumer.
\begin{itemize}
    \item \textbf{Post hoc:} Has access to all the spatio-temporal data that have been saved. However, the data movement cost is highest, and may restrict the amount of data available.
    \item \textbf{In situ / time division:} Has the highest access and lowest movement costs for spatio-temporal data as resources are shared with the producer. Access to multiple temporal steps requires additional on-node resources.
    \item \textbf{In transit / space difision:} Data access is configurable based on needs. The dedicated resource can be sized to control the amount of spatio-temporal access, as well as temporal range. Since data movement occurs over the internal network, it is much faster than I/O.
\end{itemize}

\paragraph{\textbf{Fault Tolerance}}
Fault tolerance describes the relative robustness of the system with respect to faults occurring in either the producer or the consumer.
\begin{itemize}
    \item \textbf{Post hoc:} The consumer is independent from the data producer, so fault tolerance is very high.
    \item \textbf{In situ / time division:} Because resources are shared, the producer and consumer can impact each other. This includes faults, memory corruption, memory usage, etc.
    \item \textbf{In transit / space division:} Like post hoc, the consumer is independent from the data producer. Faults occurring on the dedicated nodes will not impact the producer.
\end{itemize}


\paragraph{\textbf{Programmability}}
Programmability describes the relative ease and flexibility of connecting a simulation with visualization. This includes composing a workflow, connecting components in a workflow, and modifying the underlying data movement mechanism. Since all three classes of visualization use the same abstraction, the programmability is improved by simply  changing the engine used.

Table~\ref{table:adios_char} provides a visual representation of the relative strengths of each ADIOS engine with respect the characteristics described above. A score for each engine is assigned 
based on how well the engine performs with respect to each characteristic described above. A $``+"$ signifies a favorable evaluation, $``-"$ a less favorable evaluation, and $``0"$ for in between.


\begin{table}[b]
\centering
\caption{Characterization of each ADIOS engine}
\label{table:adios_char}
\renewcommand{\arraystretch}{1.75}
\setlength{\tabcolsep}{2.6pt}
\begin{tabular}{p{1mm}c|cccccc}
\hline
 & \cellcolor[HTML]{EFEFEF} & \multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{Engine Type}} \\
 & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{ADIOS Characteristics}} & \cellcolor[HTML]{EFEFEF}\textbf{BPFile} & \cellcolor[HTML]{EFEFEF}\textbf{HDF5} & \cellcolor[HTML]{EFEFEF}\textbf{SST} & \cellcolor[HTML]{EFEFEF}\textbf{Insitu-MPI} & \cellcolor[HTML]{EFEFEF}\textbf{SSC} & \cellcolor[HTML]{EFEFEF}\textbf{DataMan} \\ \hline
 & \textit{Spatial Access} & + & + & 0 & 0 & 0 & 0 \\
 & \textit{Temporal Fidelity} & - & - & + & + & + & 0 \\
 & \textit{Temporal Range} & + & + & 0 & 0 & 0 & 0 \\
\multirow{-4}{*}{\rotatebox[origin=c]{90}{\pbox{23mm}{\textbf{Data Access \& Data Movement}}}} & \textit{Movement} & - & - & 0 & 0 & + & 0 \\
\hline
 & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{Fault Tolerance}} & + & + & + & + & 0 & + \\
\hline
 & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{Programability}} & + & 0 & + & + & + & + \\ \hline
\end{tabular}
\end{table}

%\begin{table}[b]
%\centering
%\caption{Characterization of each ADIOS engine }
%\label{table:adios_char}
%\renewcommand{\arraystretch}{1.5}
%\setlength{\tabcolsep}{2.6pt}
%\begin{tabular}{c|cccccc}
%\hline
%\rowcolor[HTML]{EFEFEF} 
%\multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}} & \multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{Engine %Type}} \\
%\rowcolor[HTML]{EFEFEF} 
%\textbf{ADIOS Characteristics} & \textbf{BPFile} & \textbf{HDF5} & \textbf{SST} & \textbf{Insitu-MPI} & %\textbf{SSC} & \textbf{DataMan} \\ \hline
%\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}c@{}}\textbf{Data Access/Movement}\\\emph{(Spatial, %Temporal,}\\\emph{Temporal Range, Movement)}\end{tabular} & - - + - & - - + - & 0 0 0 0 & + + - + & + + - + & %0 0 0 - \\
%\cellcolor[HTML]{EFEFEF}\textbf{Fault Tolerance} & + & + & + & - & - & + \\
%\cellcolor[HTML]{EFEFEF}\textbf{Programmability} & + & + & + & + & + & + \\ \hline
%\end{tabular}
%\end{table}

\subsubsection{Visualization Perspective}
From a visualization perspective, a different set of characteristics are important (see for example, ~\cite{Kress-isav15}).
We discuss the following characteristics below: (1) scalability and resource requirements, (2) interactivity, (3) fault tolerance, and (4) programmability.

\paragraph{\textbf{Scalability and Resource Requirements}}
Scalability is defined as how efficiently the visualization task can use the allocated resources.
Resource requirements is defined as the need for additional resources beyond that of the simulation.
\begin{itemize}
    \item \textbf{Post hoc:} Has the flexibility to allocate resources suitable for the required tasks, however I/O can slow for large data.
    \item \textbf{In situ / time division:} Since the visualization must run at the scale of the visualization, the performance will depend on the operation. Communication heavy algorithms could suffer poor performance at larger scales.
    \item \textbf{In transit / space division:} Has the flexibility to allocate resources suitable for the required tasks. Since I/O is avoided, access to data can be much faster.
\end{itemize}

\paragraph{\textbf{Interactivity}}
Interactivity is defined as the ability for a user to interact with the data, select regions of interest, and plot the data to extract understanding.
\begin{itemize}
    \item \textbf{Post hoc:} Because visualization is independent from the simulation, full interactivity is possible with all data available.
    \item \textbf{In situ / time division:} Visualization has full access to all of the data that are available on the simulation resources. Due to limited available resources, the temporal range of data could be limited. If the data are shared, the simulation could be blocked while visualization occurs.
    \item \textbf{In transit / space division:} Visualization has full access to all of the spatio-temporal data that are moved to the dedicated resources. Because the data are not shared with the simulation, blocking can be avoided.
\end{itemize}


\paragraph{\textbf{Fault Tolerance}}
As above, fault tolerance refers to the robustness of the visualization to avoid impacting the simulation.
\begin{itemize}
    \item \textbf{Post hoc:} Visualization is independent from the simulation, so fault tolerance is very high.
    \item \textbf{In situ / time division:} Because resources are shared, it is possible for the visualization task to negatively impact the simulation.
    \item \textbf{In transit / space division:} Like post hoc, the visualization is independent from the simulation. Errors occurring on the dedicated nodes will not impact the simulation.
\end{itemize}

\paragraph{\textbf{Programmability}}
As above, programmability describes the ease of using visualization tools with simulation data in a variety of configurations. This includes performing visualization tasks within a workflow, connecting analysis and visualization tasks together, and the ability to access data from different sources.
 Since all three classes of visualization use the same abstraction, the programmability is improved by simply  changing the engine used.

Table~\ref{table:visualizationImportantChar} provides a visual representation of the relative strengths of each ADIOS engine with respect the important visualization characteristics described above. As above, a $``+"$ signifies a favorable evaluation, $``-"$ a less favorable evaluation, and $``0"$ for in between.
\begin{table}[htb]
\centering
\renewcommand{\arraystretch}{1.5}
\setlength{\tabcolsep}{2.3pt}
\caption{Characterization of each ADIOS engine for visualization}
\label{table:visualizationImportantChar}
\begin{tabular}{p{0.1mm}c|cccccc}
\hline
\multicolumn{1}{l}{} & \multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}} & \multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{Engine Type}} \\
\multicolumn{1}{l}{} & \cellcolor[HTML]{EFEFEF}\textbf{Visualization Characteristics} & \cellcolor[HTML]{EFEFEF}\textbf{BPFile} & \cellcolor[HTML]{EFEFEF}\textbf{HDF5} & \cellcolor[HTML]{EFEFEF}\textbf{SST} & \cellcolor[HTML]{EFEFEF}\textbf{Insitu-MPI} & \cellcolor[HTML]{EFEFEF}\textbf{SSC} & \cellcolor[HTML]{EFEFEF}\textbf{DataMan} \\ \hline
 & \textit{Data} & - & - & + & + & + & - \\
 & \textit{Communication} & + & + & + & - & - & + \\
\multirow{-3}{*}{\rotatebox[origin=c]{90}{\textbf{Scalability}}} & \textit{Resource} & + & + & - & + & + & - \\
\hline
 & \textit{Spatial} & - & - & 0 & + & + & 0 \\
 & \textit{Temporal} & - & - & 0 & + & + & 0 \\
 & \textit{Temporal Range} & + & + & 0 & - & - & 0 \\
\multirow{-4}{*}{\rotatebox[origin=c]{90}{\textbf{Interactivity}}} & \textit{Block Simulation} & + & + & + & - & - & + \\
\hline
\multicolumn{1}{l}{} & \cellcolor[HTML]{EFEFEF}\textbf{Fault Tolerance} & + & + & + & + & 0 & + \\
\hline
\multicolumn{1}{l}{} & \cellcolor[HTML]{EFEFEF}\textbf{Programability} & + & 0 & + & + & + & + \\ \hline
\end{tabular}
\end{table}


%\begin{table}[h]
%\centering
%\label{table:}
%\renewcommand{\arraystretch}{1.5}
%\setlength{\tabcolsep}{2.3pt}
%\begin{tabular}{c|cccccc}
%\hline
%\rowcolor[HTML]{EFEFEF} 
%\multicolumn{1}{l|}{\cellcolor[HTML]{EFEFEF}} & %\multicolumn{6}{c}{\cellcolor[HTML]{EFEFEF}\textbf{Engine Type}} \\
%\rowcolor[HTML]{EFEFEF} 
%\textbf{Visualization Characteristics} & %\multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}\textbf{BPFile}} & %\multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}\textbf{HDF5}} & %\multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}\textbf{SST}} & %\multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}\textbf{Insitu-MPI}} & %\multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}\textbf{SSC}} & %\multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}\textbf{DataMan}} \\ \hline
%\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}c@{}}\textbf{Scalability}\\ \emph{(Data, %Communication, Resource)}\end{tabular} & - + + & - + + & + + - & + - + & + - + & - + - %\\
%\cellcolor[HTML]{EFEFEF}\begin{tabular}[c]{@{}c@{}}\textbf{Interactivity}\\\emph{(Spati%al, Temporal,}\\\emph{Temporal Range, Block Sim.)}\end{tabular} & - - + + & - - + + & 0 %0 0 + & + + - - & + + - -& 0 0 0 + \\
%\cellcolor[HTML]{EFEFEF}\textbf{Fault Tolerance} & + & + & + & - & - & + \\
%\cellcolor[HTML]{EFEFEF}\textbf{Programmability} & + & + & + & + & + & + \\ \hline
%\end{tabular}
%\end{table}



\subsubsection{In Situ Data Placement and the Associated Performance Implications}
\label{sec:implications}
Placement (in-line, in-transit, hybrid methods) is an important aspect to consider when planning for the use of in situ techniques. Performance can vary drastically depending on what analysis operations are used, how often they are performed, and at what scale they are performed. This performance difference is due primarily to the scaling characteristics of the analysis algorithms in relation to that of the underlying simulation, and can have a large effect on the overall cost of a simulation plus its visualization and analysis components. 

In a work by Kress et al.~\cite{kress2019comparing} they look specifically at the cost of performing isocontours and ray tracing with parallel compositing both in-line and in-transit, and observe large cost variations based on placement as the simulation was scaled. Their work found that as the simulation was scaled to 16K cores, that visualization algorithms suffered large slowdowns in-line. However, if the data was transferred from the simulation over the network to a set of dedicated visualization nodes that the visualization routines completed much faster. They bring up a couple of general guidelines in that work: (1) if fastest time to solution is your goal at scale, moving the data and performing the visualization in-transit is the best solution; (2) if the lowest total combined cost of the simulation and visualization routines are the overall goal, the solution becomes more complicated. In general though, as the simulation scales if the visualization routines do not scale as well, moving the visualization routine to a smaller in-transit allocation is the best choice. However, careful consideration has to be given to how large of an in-transit allocation to reserve, and how often the visualization should be performed. A follow on work~\cite{kress2020Cost} develops a cost model to evaluate the use of in situ methods at scale.


\subsection{Code Examples}
\label{sec:adios:code}
This section contains examples using ADIOS to read and write data.
The first example, shown in Listing ~\ref{code:writeExampleFile}, illustrates how a simulation code would write output data to disk using the BPFile engine.
The engine type is specified in line~\ref{code:writeExampleFile:engineType}.

\lstset{language=C++,
        basicstyle=\ttfamily\scriptsize,
        showstringspaces=false,
        numbers=left,
        keywordstyle=\color{blue}\ttfamily,
        stringstyle=\color{red}\ttfamily,
        commentstyle=\color{magenta}\ttfamily,
        morecomment=[l][\color{magenta}]{\#},
        escapechar=|
}

\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,label={cxxAPI},caption={Example of simulation writing outputs to a file.}, label=code:writeExampleFile]
adios2::ADIOS adios(MPI_COMM_WORLD); |\label{code:writeExampleFile:configType}|
// Declare named IO process
adios2::IO io = adios.DeclareIO("output");

// Declare output type and size.
adios2::Variable<double> var = 
  io.DefineVariable<double>("var", globalDims, offset, localDims);
                                

// Set engine output to BPFile
io.SetEngine("BPFile"); |\label{code:writeExampleFile:engineType}|
adios2::Engine engine = io.Open("output.bp", adios2::Mode::Write);

// Run Simulation
for(...)
{
   double *data = Simulation();
   
   engine.BeginStep();
   engine.Put(var, data);
   engine.EndStep();
}
engine.Close();
\end{lstlisting}
\end{minipage}

Listing~\ref{code:readExampleFile} shows a program that reads data from the output file and performs visualization on the data.

\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,label={cxxAPI},caption={Example of a visualization  program reading data from a file}, label=code:readExampleFile]
adios2::ADIOS adios(MPI_COMM_WORLD); |\label{code:readExampleFile:configType}|
adios2::IO io = adios.DeclareIO("input"); //Declare named IO process
io.SetEngine("BPFile"); |\label{code:readExampleFile:engineType}|
adios2::Engine reader = io.Open("output.bp", adios2::Mode::Read);

std::vector<double> data;

while (reader.BeginStep(adios2::StepMode::Read) == adios2::StepStatus::OK)
{
  adios2::Variable<double> var = reader.InquireVariable<double>("var");
  if(var)
    reader.Get<double>(var, data);
  reader.EndStep();
  
  Visualize(data);
}
engine.Close();
\end{lstlisting}
\end{minipage}

To change the simulation output mode from file based to the SST in situ mode, the only change required in Listings~\ref{code:writeExampleFile} and ~\ref{code:readExampleFile}, is to change lines~\ref{code:writeExampleFile:engineType} and ~\ref{code:readExampleFile:engineType}, respectively, from
\begin{lstlisting}[numbers=none]
io.SetEngine("BPFile");
\end{lstlisting}
to 
\begin{lstlisting}[numbers=none]
io.SetEngine("SST");
\end{lstlisting}

The visualization program will now read the outputs produced by the simulation from the ADIOS stream named "output.bp", which in this case, will be coming from the SST engine in the simulation writer process. All of the engine types support by ADIOS can be changed in this way.

An alternative to specifying engine type in the source code is to use a configuration file,  which is parsed at runtime and specifies the engines type and IO processes to be used. Both XML and YAML are supported as configuration file formats.
the only change required in Listings~\ref{code:writeExampleFile} and ~\ref{code:readExampleFile}, is to change line~\ref{code:writeExampleFile:configType}
%and ~\ref{code:readExampleFile:configType}, respectively,
from
\begin{lstlisting}[numbers=none]
adios2::ADIOS adios(MPI_COMM_WORLD);
\end{lstlisting}
to 
\begin{lstlisting}[numbers=none]
adios2::ADIOS adios("config.xml", MPI_COMM_WORLD);
\end{lstlisting}

%Listings~\ref{code:writeExampleXML} and~\ref{code:readExampleXML} show the use of an XML file ("config.xml") being used to configure ADIOS on line 1.
This allows the underlying data movement mechanism to be changed without re-compiling anything.

%\begin{lstlisting}[frame=single,label={cxxAPI},caption={Example of simulation writing outputs using an XML %configuration file.}, label=code:writeExampleXML]
%adios2::ADIOS adios("config.xml", MPI_COMM_WORLD);
%adios2::IO io = adios.DeclareIO("output");
%adios2::Variable<double> var = 
%  io.DefineVariable<double>("var", globalDims, offset, localDims);
%adios2::Engine engine = io.Open("output.bp", adios2::Mode::Write);
%
%// Run Simulation
%for(...)
%{
%   double *data = Simulation();
%   
%   engine.BeginStep();
%   engine.Put(var, data);
%   engine.EndStep();
%}
%engine.Close();
%\end{lstlisting}

%\begin{lstlisting}[frame=single,label={cxxAPI},caption={Example of a visualization  program reading data %using an XML configuration.}, label=code:readExampleXML]
%adios2::ADIOS adios("config.xml", MPI_COMM_WORLD);
%adios2::IO io = adios.DeclareIO("input"); //Declare named IO process
%adios2::Engine reader = io.Open("output.bp", adios2::Mode::Read);
%
%std::vector<double> data;
%
%while (reader.BeginStep(adios2::StepMode::Read) == adios2::StepStatus::OK)
%{
%  adios2::Variable<double> var = reader.InquireVariable<double>("var");
%  if(var)
%    reader.Get<double>(var, data);
%  reader.EndStep();
%  
%  Visualize(data);
%}
%engine.Close();
%\end{lstlisting}

\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,label={configXML},caption={Configuration file, "config.xml" for examples shown in Listing~\ref{code:writeExampleFile} and ~\ref{code:readExampleFile}}, label=code:XML]

<!-- adios2 config file in XML format -->
<?xml version="1.0"?>
<adios-config>
    <io name="output">
        <!-- engine type can be set at runtime: BPFile, SST, etc. -->
        <engine type="BPFile"> |\label{code:xmlExampleFile:engineType}|
        </engine>
    </io>
    <io name="input">
        <engine type="BPFile" />
    </io>
</adios-config>

\end{lstlisting}
\end{minipage}

\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,label={configYAML},caption={Alternative configuration file, "config.yaml" for examples shown in Listing~\ref{code:writeExampleFile} and ~\ref{code:readExampleFile}}, label=code:YAML]
---
# adios2 config file in YAML format

- IO: "output"
  Engine:
    # engine type can be set at runtime: BPFile, SST, etc.
    Type: "BPFile" |\label{code:yamlExampleFile:engineType}|

- IO: "input"
  Engine:
    Type: "BPFile"

\end{lstlisting}
\end{minipage}

Basic XML and YAML configuration files for ADIOS are shown in Listings~\ref{code:XML} and~\ref{code:YAML} respectively. Changing the "type" field on line~\ref{code:xmlExampleFile:engineType} from "BPFile" to "SST" will configure ADIOS to use the SST engine when the executables are run.

%In order to avoid modifications to the simulation or visualization source code, the configuration of engines and IO processes can be specified using an XML or YAML file. In code Listings~\ref{code:writeExampleXML} and ~\ref{code:readExampleXML} shows examples using a file named "config.xml" (see Listing~\ref{code:XML} that contains the configuration of engines that are used.

Listing~\ref{pythonAPI} illustrates how to read ADIOS data using the Python high-level API.
ADIOS provides a ``pythonic'' interface of an iterable container of steps using a generic ``read'' function that always return a numpy array for easy integration with the Python data analysis ecosystem. Similarly, switching between Engines is done through a parameter in the open function or using a config file as described above.

\lstset{language=Python,
                showstringspaces=false,
                basicstyle=\ttfamily\scriptsize,
                keywordstyle=\color{blue}\ttfamily,
                stringstyle=\color{red}\ttfamily,
                commentstyle=\color{green}\ttfamily,
                morecomment=[l][\color{green}]{\#}
}


\begin{minipage}{\linewidth}
\begin{lstlisting}[frame=single,label={pythonAPI},caption={Python High-Level API Read Example}]
import adios2

with adios2.open("euler.bp", "r", engine_type="BPFile") as fh:

    for fstep in fh:
        
        # retrieve current step
        step = fstep.current_step()

        # inspect variables dictionary in current step 
        step_vars = fstep.available_variables()
        for name, info in step_vars.items():
            print("variable_name: " + name)
            for key, value in info.items():
                print("\t" + key + ": " + value)
            print("\n")

        if( step == 0 ):
            size_in = fh_step.read("size")

        # read variables in current step
        # returning a numpy array for easy integration
        # with data science frameworks (e.g. pandas, scipy)
        T = fstep.read("T")
        
\end{lstlisting}
\end{minipage}






\begin{comment}
Proposed new outline for this section:
ADIOS I/O abstraction
\begin{itemize}
    \item Here are some things you need to worry about doing vis (move some of the stuff in ADIOS ecosystem up into here)
    \item We have invested in ADIOS because it makes a lot of the things above easier
\item ADIOS details
\begin{itemize}
    \item Data movement engines
    \item Advanced data management services (compression, adis, openPMD)
\end{itemize}
\item Description of each engine
\item characterize engines (wrt to ADIOS)
\begin{itemize}
\item Data access and movement (combine)
\item Fault tolerance
\item Programability: Flexibility/coordination: change engine w/o recompiling
\end{itemize}
\item Things that vis cares about:
\begin{itemize}
\item scalability (combine w/ resource req?)
\item resource requirements
\item interactivity
\item Programability: Flexibility/coordination/integration
\item fault tolerance
\end{itemize}
    \item Data access performance: (combine data access and movement)
    \item scalability 
    \item tie back to the vis stuff
\end{itemize}
\newpage
\end{comment}